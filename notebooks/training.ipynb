{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torchvision import datasets,models,transforms\n",
    "import pandas as pd \n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from src import config \n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            filename      label\n0    0-with-mask.jpg  with_mask\n1    1-with-mask.jpg  with_mask\n2   10-with-mask.jpg  with_mask\n3  100-with-mask.jpg  with_mask\n4  101-with-mask.jpg  with_mask",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0-with-mask.jpg</td>\n      <td>with_mask</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1-with-mask.jpg</td>\n      <td>with_mask</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10-with-mask.jpg</td>\n      <td>with_mask</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100-with-mask.jpg</td>\n      <td>with_mask</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>101-with-mask.jpg</td>\n      <td>with_mask</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join('..',config.TRAINING_DATA,'train.csv'))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                  filename      label\n0  augmented_image_227.jpg  with_mask\n1  augmented_image_228.jpg  with_mask\n2   augmented_image_23.jpg  with_mask\n3  augmented_image_230.jpg  with_mask\n4  augmented_image_232.jpg  with_mask",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>augmented_image_227.jpg</td>\n      <td>with_mask</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>augmented_image_228.jpg</td>\n      <td>with_mask</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>augmented_image_23.jpg</td>\n      <td>with_mask</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>augmented_image_230.jpg</td>\n      <td>with_mask</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>augmented_image_232.jpg</td>\n      <td>with_mask</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join('..',config.TESTING_DATA,'test.csv'))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]), \n",
    "    'test' : transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Dataset ImageFolder\n    Number of datapoints: 1096\n    Root location: ../data/train\n    StandardTransform\nTransform: Compose(\n               RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n               ToTensor()\n               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n           )"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "image_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Dataset ImageFolder\n    Number of datapoints: 276\n    Root location: ../data/test\n    StandardTransform\nTransform: Compose(\n               Resize(size=256, interpolation=PIL.Image.BILINEAR)\n               CenterCrop(size=(224, 224))\n               ToTensor()\n               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n           )"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "image_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                             batch_size=4, \n",
    "                                             shuffle=True, \n",
    "                                             num_workers=4) \n",
    "               for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['with_mask', 'without_mask']"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'train': 1096, 'test': 276}"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_ft = models.resnet101(pretrained=True)\n",
    "model_ft = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# num_frts = model_ft.fc.in_features\n",
    "num_frts = model_ft.classifier[1].in_features\n",
    "model_ft.fc = nn.Linear(num_frts, len(class_names))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_ft = torch.optim.Adagrad(model_ft.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "Model",
     "Training"
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    new_freeze_state = None\n",
    "    prev_freeze_state = False\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "        \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            training_losses.append(epoch_loss) if phase=='train' else validation_losses.append(epoch_loss)\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc:{:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            \n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model)\n",
    "    \n",
    "    return model,training_losses,validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\somya\\.conda\\envs\\facemaskdetection\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:118: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3614 Acc:0.8433\n",
      "\n",
      "test Loss: 0.0536 Acc:0.9928\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.1944 Acc:0.9203\n",
      "\n",
      "test Loss: 0.0330 Acc:0.9964\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.1077 Acc:0.9561\n",
      "\n",
      "test Loss: 0.0331 Acc:0.9964\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.0968 Acc:0.9543\n",
      "\n",
      "test Loss: 0.0179 Acc:0.9928\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.0932 Acc:0.9552\n",
      "\n",
      "test Loss: 0.0121 Acc:1.0000\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.0836 Acc:0.9606\n",
      "\n",
      "test Loss: 0.0232 Acc:1.0000\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.0709 Acc:0.9624\n",
      "\n",
      "test Loss: 0.0188 Acc:1.0000\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.0699 Acc:0.9705\n",
      "\n",
      "test Loss: 0.0112 Acc:1.0000\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.0552 Acc:0.9722\n",
      "\n",
      "test Loss: 0.0114 Acc:1.0000\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.0901 Acc:0.9508\n",
      "\n",
      "test Loss: 0.0092 Acc:1.0000\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.0660 Acc:0.9669\n",
      "\n",
      "test Loss: 0.0105 Acc:1.0000\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.0541 Acc:0.9758\n",
      "\n",
      "test Loss: 0.0063 Acc:1.0000\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.0603 Acc:0.9705\n",
      "\n",
      "test Loss: 0.0058 Acc:1.0000\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 0.0796 Acc:0.9526\n",
      "\n",
      "test Loss: 0.0050 Acc:1.0000\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 0.0693 Acc:0.9642\n",
      "\n",
      "test Loss: 0.0072 Acc:1.0000\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 0.0558 Acc:0.9705\n",
      "\n",
      "test Loss: 0.0079 Acc:1.0000\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.0685 Acc:0.9678\n",
      "\n",
      "test Loss: 0.0047 Acc:1.0000\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.0530 Acc:0.9749\n",
      "\n",
      "test Loss: 0.0053 Acc:1.0000\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.0659 Acc:0.9651\n",
      "\n",
      "test Loss: 0.0047 Acc:1.0000\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 0.0667 Acc:0.9705\n",
      "\n",
      "test Loss: 0.0060 Acc:1.0000\n",
      "\n",
      "Training complete in 22.000000m 30s\n",
      "Best val acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "model_ft,training_losses,validation_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft,os.path.join('..','saved_models',f'facemaskdetection_new_mask_types{datetime.now()}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Training History')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(training_losses, label='train loss')\n",
    "ax.plot(validation_losses, label='validation loss')\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "ax.set_ylim([-0.05, 1.05])\n",
    "ax.legend()\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Epoch')\n",
    "fig.suptitle('Training History', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('facemaskdetection': conda)",
   "language": "python",
   "name": "python38364bitfacemaskdetectioncondabbc34c603e8842f99d319fd75ca39243"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}